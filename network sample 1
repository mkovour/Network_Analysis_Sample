# Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import networkx as nx  # For network analysis
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from scipy.stats import spearmanr


def load_and_clean_data(filepath: str) -> pd.DataFrame:
    """
    Load the dataset and clean it by removing rows with missing values.
    
    Parameters:
        filepath (str): Path to the CSV file.
        
    Returns:
        pd.DataFrame: Cleaned dataset.
    """
    try:
        df = pd.read_csv(filepath)
        df_clean = df.dropna()
        return df_clean
    except FileNotFoundError:
        raise ValueError(f"File not found at {filepath}")
    except Exception as e:
        raise ValueError(f"Error loading data: {e}")


def normalize_data(df: pd.DataFrame, target_column: str) -> tuple[pd.DataFrame, pd.Series]:
    """
    Normalize features using StandardScaler and separate the target variable.
    
    Parameters:
        df (pd.DataFrame): Dataset.
        target_column (str): Name of the target column.
        
    Returns:
        tuple: Normalized features (pd.DataFrame) and target variable (pd.Series).
    """
    if target_column not in df.columns:
        raise ValueError(f"Target column '{target_column}' not found in the dataset.")
    
    scaler = StandardScaler()
    X = df.drop(columns=[target_column])
    y = df[target_column]
    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)
    return X_scaled, y


def check_distribution(df: pd.DataFrame) -> None:
    """
    Plot histograms to check the distribution of features.
    
    Parameters:
        df (pd.DataFrame): Dataset.
    """
    df.hist(bins=30, figsize=(20, 15))
    plt.tight_layout()
    plt.show()


def visualize_data(X: pd.DataFrame, y: pd.Series) -> None:
    """
    Visualize data using bar and scatter plots.
    
    Parameters:
        X (pd.DataFrame): Feature matrix.
        y (pd.Series): Target variable.
    """
    # Bar plot for mean values of features
    X.mean().plot(kind='bar', figsize=(12, 6), color='skyblue')
    plt.title("Mean Values of Biomarkers")
    plt.ylabel("Mean")
    plt.show()
    
    # Scatter plots for each feature against the target
    for col in X.columns:
        plt.figure(figsize=(6, 4))
        sns.scatterplot(x=X[col], y=y)
        plt.title(f"Scatter Plot - {col} vs {y.name}")
        plt.xlabel(col)
        plt.ylabel(y.name)
        plt.show()


def random_forest_model(X: pd.DataFrame, y: pd.Series) -> RandomForestRegressor:
    """
    Train a Random Forest model and evaluate its performance.
    
    Parameters:
        X (pd.DataFrame): Feature matrix.
        y (pd.Series): Target variable.
        
    Returns:
        RandomForestRegressor: Trained Random Forest model.
    """
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_model.fit(X_train, y_train)
    y_pred = rf_model.predict(X_test)
    
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print(f"Random Forest Model Performance:\nMSE: {mse:.2f}, R2: {r2:.2f}")
    
    return rf_model


def plot_feature_importance(model: RandomForestRegressor, X: pd.DataFrame) -> list[str]:
    """
    Plot feature importance from a trained Random Forest model.
    
    Parameters:
        model (RandomForestRegressor): Trained model.
        X (pd.DataFrame): Feature matrix.
        
    Returns:
        list[str]: Top 10 important features.
    """
    importances = model.feature_importances_
    feature_importance_df = pd.DataFrame({
        'Feature': X.columns,
        'Importance': importances
    }).sort_values(by='Importance', ascending=False)
    
    plt.figure(figsize=(10, 6))
    sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(10))
    plt.title('Top 10 Feature Importance - Random Forest')
    plt.show()
    
    return feature_importance_df['Feature'].head(10).tolist()


def spearman_correlation_analysis(df: pd.DataFrame, top_features: list[str]) -> None:
    """
    Perform Spearman Correlation Analysis on top features.
    
    Parameters:
        df (pd.DataFrame): Dataset.
        top_features (list[str]): List of top features to analyze.
    """
    spearman_corr = df[top_features].corr(method='spearman')
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(spearman_corr, annot=True, cmap="coolwarm", fmt=".2f")
    plt.title("Spearman Correlation Heatmap of Top Features")
    plt.show()


def network_analysis(df: pd.DataFrame, top_features: list[str]) -> None:
    """
    Perform network analysis for variable interactions.
    
    Parameters:
        df (pd.DataFrame): Dataset.
        top_features (list[str]): List of top features to analyze.
    """
    corr_matrix = df[top_features].corr()
    G = nx.Graph()
    threshold = 0.5

    for i, feature1 in enumerate(top_features):
        for j, feature2 in enumerate(top_features):
            if i != j and np.abs(corr_matrix.iloc[i, j]) > threshold:
                G.add_edge(feature1, feature2, weight=corr_matrix.iloc[i, j])
    
    plt.figure(figsize=(10, 8))
    pos = nx.spring_layout(G)
    nx.draw_networkx(G, pos, with_labels=True, node_color="skyblue", edge_color="gray", node_size=2000, font_size=10)
    plt.title("Network Analysis of Top Biomarkers Interaction")
    plt.show()


def main(filepath: str, target_column: str) -> None:
    """
    Main workflow to execute data loading, cleaning, analysis, and modeling.
    
    Parameters:
        filepath (str): Path to the dataset file.
        target_column (str): Name of the target column.
    """
    df_clean = load_and_clean_data(filepath)
    X_scaled, y = normalize_data(df_clean, target_column)
    check_distribution(X_scaled)
    visualize_data(X_scaled, y)
    rf_model = random_forest_model(X_scaled, y)
    top_features = plot_feature_importance(rf_model, X_scaled)
    spearman_correlation_analysis(df_clean, top_features)
    network_analysis(df_clean, top_features)


# Example usage:
# filepath = 'biomarker_data.csv'
# target_column = 'Aging'
# main(filepath, target_column)
